{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eda\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use eda module to load dataset \n",
    "df = eda.load_dataset(url=\"https://raw.github.com/ant1code/tweet-sentiment/master/data/train.csv\")\n",
    "\n",
    "# data preprocessing: removing na, mapping categorical variable to numerical\n",
    "df = eda.preprocess_data(df)\n",
    "\n",
    "# normalizing the tweets (removing unnecessary words, lemmatizing)\n",
    "stop_words = eda.get_stop_words()\n",
    "df = eda.normalize(df, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spent the entire morning in a meeting w/ a ven...</td>\n",
       "      <td>1</td>\n",
       "      <td>spent entire morning meeting w vendor boss not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oh! Good idea about putting them on ice cream</td>\n",
       "      <td>2</td>\n",
       "      <td>oh good idea put ice cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>says good (or should i say bad?) afternoon!  h...</td>\n",
       "      <td>1</td>\n",
       "      <td>say good say bad afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont think you can vote anymore! i tried</td>\n",
       "      <td>0</td>\n",
       "      <td>dont think vote anymore try</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha better drunken tweeting you mean?</td>\n",
       "      <td>2</td>\n",
       "      <td>haha well drunken tweet mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  \\\n",
       "0  Spent the entire morning in a meeting w/ a ven...          1   \n",
       "1      Oh! Good idea about putting them on ice cream          2   \n",
       "2  says good (or should i say bad?) afternoon!  h...          1   \n",
       "3         i dont think you can vote anymore! i tried          0   \n",
       "4             haha better drunken tweeting you mean?          2   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  spent entire morning meeting w vendor boss not...  \n",
       "1                         oh good idea put ice cream  \n",
       "2                         say good say bad afternoon  \n",
       "3                        dont think vote anymore try  \n",
       "4                       haha well drunken tweet mean  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek at dataset \n",
    "# recall that negative: 0, neutral: 1, positive: 2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "bow = vectorizer.fit_transform(df['lemmatized'])\n",
    "sentiment = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21359"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3749"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5)\n",
    "bow = vectorizer.fit_transform(df['lemmatized'])\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27485x3749 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 166170 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bow, sentiment, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7005842795722632"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(random_state=42, bootstrap=False)\n",
    "classifier.fit(X_train,y_train)\n",
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:  5.7min remaining:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  7.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  7.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs...\n",
       "                                        'max_features': ['sqrt'],\n",
       "                                        'min_samples_leaf': [16, 32],\n",
       "                                        'min_samples_split': [320, 640, 1280,\n",
       "                                                              2560],\n",
       "                                        'n_estimators': [2000, 2010, 2020, 2030,\n",
       "                                                         2040, 2050, 2060, 2070,\n",
       "                                                         2080, 2090, 2100, 2110,\n",
       "                                                         2120, 2130, 2140, 2150,\n",
       "                                                         2160, 2170, 2180, 2190,\n",
       "                                                         2201, 2211, 2221, 2231,\n",
       "                                                         2241, 2251, 2261, 2271,\n",
       "                                                         2281, 2291, ...]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BONUS: hyperparameter optimization\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 2000, stop = 4000, num = 200)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(100, 2000, num = 100)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [320, 640, 1280, 2560]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [16, 32]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = classifier, param_distributions = random_grid,\n",
    "                                   cv = 3, verbose = 2, random_state = 42, \n",
    "                                   n_iter=3, n_jobs= -1, return_train_score = True)\n",
    "\n",
    "random_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 3587,\n",
       " 'min_samples_split': 640,\n",
       " 'min_samples_leaf': 16,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 1558,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the best of the 6 trained models\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
